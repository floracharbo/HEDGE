# run configuration
data_types: ["loads", "car", "gen"]

syst:
  H: 24

train_set_size: 0.8  # how muuch of the data to use for GAN training vs testing
n_intervals: 50  # number of intervals in car factor transition matrix

n_rows: # number of rows to import xin each data file (limit numbers e.g. for debugging)
  gen: all # 172718543
  loads: all # 300267349 all
  car: all # 4449164 all

fill_type: # interpolate linearly to fill in errors instead of looking at day/week before
  gen: lin_interp
  loads: lin_interp

prob_test_filling_in: 0.01  # number between 0 and 1 ; what proportion of points we evaluate

n_cpu:  # to limit the number of CPUs being used

n_clus:  # number of behavioural clusters
  loads: 4
  car: 3

plots: True
do_test_filling_in: False
parallel: False
do_heat_map: True  # plot data available - this is computationally expensive
test_factor_distr: False
candidate_factor_distributions:
save_intermediate_outs: True  # this makes the data generation more tractable
max_size_chunk: 5.e+6  # reduce the size of individual data chunks that are processed to reduce RAM requirements.
gan_generation_profiles: True

kurtosis: False
brackets_definition: 'percentile'
# linspace or percentile
car:
  max_power_cutoff: 50  # in kW (average over one time step)
  max_daily_energy_cutoff: 200  # in kWh (over one day)
high_res: True
n_consecutive_days: [2]
# 2,3
months: [1]